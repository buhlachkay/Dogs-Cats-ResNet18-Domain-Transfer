{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Computer Vision:  HW 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Science: COMS W 4995 006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Due: November 10, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: Telling Cats from Dogs using ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Here you will build a classifier that can distinguish between pictures of dogs and cats. You will use a ConvNet (Resnet18) that was pre-trained ImageNet. Your task will be to re-architect the network to solve your problem. You are required to do this in Pytorch or Tensorflow. To do this you will:\n",
    "\n",
    "    a) Make a training, validation, and test sets for your dataset by using images from the link below, with 10,000 images of cats and 10,000 images of dogs. Use 8,000 images of each category for traning, 1,000 of each category for validation, 1,000 images of each category for testing. You are to randomly shuffle the data and choose the splits yourself.  \n",
    "\n",
    "    b) Take ResNet18 network architecture. See https://pytorch.org/vision/stable/models.html.\n",
    "    \n",
    "    c) Load in the pre-trained weights. See again https://pytorch.org/vision/stable/models.html. \n",
    "    \n",
    "    d) Add a fully connected layer followed by a final sigmoid layer **to replace** the last fully connected layer and 1000 category softmax layer that was used when the network was trained on ImageNet.\n",
    "    \n",
    "    e) Freeze all layers except the last two that you added.\n",
    "    \n",
    "    f) Fine-tune the network on your cats vs. dogs image data.\n",
    "    \n",
    "    g) Evaluate the accuracy on the test set.\n",
    "    \n",
    "    h) Unfreeze all layers.\n",
    "    \n",
    "    i) Continue fine-tuning the network on your cats vs. dogs image data.\n",
    "    \n",
    "    j) Evaluate the accuracy on the test set.\n",
    "    \n",
    "    k) Use your validation set throughout to decide on when to stop training the network at various stages.\n",
    "    \n",
    "    l) Comment your code and make sure to include accuracy, a few sample mistakes, and anything else you would like to add.\n",
    "    \n",
    "    m) Experiment with what you keep and what you replace as part of your network surgery. Does the training work better if you do not remove the last fully connected layer?\n",
    "    \n",
    "    n) Try this using any other CNN network you like. Take whatever path you like to get to your final model. Evaluate its accuracy. Do not ask which network you should use.\n",
    "\n",
    "\n",
    "2. (Extra Credit): Repeat the assignment but replace ResNet18 with a Vision Transformer (ViT). See https://huggingface.co/docs/transformers/model_doc/vit and https://github.com/NielsRogge/Transformers-Tutorials/tree/master/VisionTransformer. \n",
    "\n",
    "\n",
    "3. (Extra Credit): Repeat the assignment but replace ResNet18 with BEiT. See https://huggingface.co/docs/transformers/model_doc/beit.\n",
    "\n",
    "Downloads: You can get your image data from:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## IMPORTS ##############################################\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### DATA AQUISITION & TORCH CONFIG ##############################################\n",
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "\n",
    "dataPreprocessingTransformations = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/Users/blake/Documents/COMS 4995 - DL CV/HW5/dogs-vs-cats/'\n",
    "imgDatasets = {i: datasets.ImageFolder(os.path.join(data_dir, i),dataPreprocessingTransformations[i])\n",
    "                  for i in ['train','valid','test']}\n",
    "\n",
    "dataloaders = {i: torch.utils.data.DataLoader(imgDatasets[i], batch_size=64,shuffle=True, num_workers=0) for i in ['train','valid','test']}\n",
    "\n",
    "partitionLens = {i: len(imgDatasets[i]) for i in ['train', 'valid','test']} # data is already split up into correct 8000-1000-1000 partitions\n",
    "labelStrings = imgDatasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## FUNCTION DEFINITION ##############################################\n",
    "\n",
    "def train(model, loss, optimizer, scheduler, numEpochs):\n",
    "    savedModels = copy.deepcopy(model.state_dict())\n",
    "    bestAccuracy = 0\n",
    "\n",
    "    for epoch in range(numEpochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, numEpochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            numCorrect = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "\n",
    "                # Reduce overhead by sending data to GPU\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward Prop\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    curLoss = loss(outputs, labels)\n",
    "\n",
    "                    # Back Prop (if needed/training)\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        curLoss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Keep Track of Accuracy\n",
    "                numCorrect += torch.sum(preds == labels.data)\n",
    "\n",
    "            # Step the decay scheduler forward if we're training for the epoch\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # Obtain the net accuracy at this epoch\n",
    "            netAccuracy = float(numCorrect) / partitionLens[phase]\n",
    "\n",
    "            print('{} accuracy: {:.2f}%'.format(phase, 100*netAccuracy))\n",
    "\n",
    "            # Deep copy model if it has the best accuracy\n",
    "            if phase == 'valid' and netAccuracy > bestAccuracy:\n",
    "                savedModels = copy.deepcopy(model.state_dict())\n",
    "                bestAccuracy = netAccuracy\n",
    "\n",
    "\n",
    "    print('Best validation accurracy: {:2f}%'.format(100*bestAccuracy))\n",
    "\n",
    "    # Return best model\n",
    "    model.load_state_dict(savedModels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()   # Evaluation mode\n",
    "\n",
    "    numCorrect = 0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dataloaders[\"test\"]:\n",
    "\n",
    "        # Reduce overhead by sending data to GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        torch.set_grad_enabled(False)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "        # Keep track of number correct\n",
    "        numCorrect += torch.sum(preds == labels.data)\n",
    "\n",
    "\n",
    "    netAccuracy = float(numCorrect) / partitionLens[\"test\"]\n",
    "\n",
    "    print('Testing Accuracy: {:.2f}%'.format(100*netAccuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "----------\n",
      "train accuracy: 87.04%\n",
      "valid accuracy: 96.70%\n",
      "Epoch 2/2\n",
      "----------\n",
      "train accuracy: 92.88%\n",
      "valid accuracy: 97.10%\n",
      "Best validation accurracy: 97.102897%\n",
      "Epoch 1/2\n",
      "----------\n",
      "train accuracy: 93.44%\n",
      "valid accuracy: 97.10%\n",
      "Epoch 2/2\n",
      "----------\n",
      "train accuracy: 93.01%\n",
      "valid accuracy: 97.00%\n",
      "Best validation accurracy: 97.102897%\n",
      "Testing Accuracy: 97.42%\n"
     ]
    }
   ],
   "source": [
    "########################################## DOMAIN TRANSFERED NETWORK ##############################################\n",
    "## Train the last layer only\n",
    "\n",
    "# Obtain model\n",
    "newModel = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers\n",
    "for param in newModel.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace last layer with new, unfrozen layer\n",
    "oldFCInputCount = newModel.fc.in_features\n",
    "totalClassCount = 2\n",
    "newModel.fc = nn.Linear(oldFCInputCount, totalClassCount)\n",
    "\n",
    "\n",
    "# Send to GPU to reduce overhead\n",
    "newModel = newModel.to(device)\n",
    "\n",
    "# Define sigmoid for loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer for back propogation\n",
    "optimizer_conv = optim.SGD(newModel.fc.parameters(), lr=1e-3, momentum=0.8)\n",
    "\n",
    "# Use decaying scheduler\n",
    "exponentialDecayScheduler = lr_scheduler.StepLR(optimizer_conv, step_size=8, gamma=1e-1)\n",
    "\n",
    "# Train last layer\n",
    "newModel = train(newModel, loss, optimizer_conv, exponentialDecayScheduler, numEpochs=2)\n",
    "\n",
    "#########################################################################################################\n",
    "## Train all layers\n",
    "\n",
    "# Unfreeze all layers\n",
    "for param in newModel.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Send to GPU to reduce overhead\n",
    "newModel = newModel.to(device)\n",
    "\n",
    "# Define sigmoid for loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer for back propogation\n",
    "optimizer_conv = optim.SGD(newModel.fc.parameters(), lr=1e-5, momentum=0.8)\n",
    "\n",
    "# Use decaying scheduler\n",
    "exponentialDecayScheduler = lr_scheduler.StepLR(optimizer_conv, step_size=8, gamma=1e-2)\n",
    "\n",
    "# Train all layers\n",
    "newModel = train(newModel, loss, optimizer_conv,exponentialDecayScheduler, numEpochs=2)\n",
    "\n",
    "#########################################################################################################\n",
    "# Test model on test data\n",
    "test(newModel)\n",
    "\n",
    "\n",
    "# The model is fairly accurate; however, more epoch cycles/training is probably required to increase the accuracy\n",
    "# further. The sample mistakes are not necessarily indistinguishable and can be solved with increasing the train time.\n",
    "# I currently am not increasing the train time (number of epochs) heavily due to my own computational limits.\n",
    "# I believe the network isn't fine-tuned enough on the dog/cats and is still closer to ResNet18 which allows for more\n",
    "# error room due to the 5 top class limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "train accuracy: 90.25%\n",
      "valid accuracy: 89.21%\n",
      "Best validation accurracy: 89.210789%\n"
     ]
    }
   ],
   "source": [
    "########################## DOMAIN TRANSFERED NETWORK + MAX POOLING REPLACEMENT ##############################\n",
    "## Train the last layer only\n",
    "\n",
    "# Obtain model\n",
    "newModel = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers\n",
    "for param in newModel.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Extra Replacement of average pooling layer (more averaging)\n",
    "newModel.avgpool = nn.AdaptiveAvgPool2d((5,5))\n",
    "\n",
    "# Replace last layer with new, unfrozen layer\n",
    "oldFCInputCount = newModel.fc.in_features * 25 # multiplied by 25 due to max pooling\n",
    "totalClassCount = 2\n",
    "newModel.fc = nn.Linear(oldFCInputCount, totalClassCount)\n",
    "\n",
    "\n",
    "# Send to GPU to reduce overhead\n",
    "newModel = newModel.to(device)\n",
    "\n",
    "# Define sigmoid for loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer for back propogation\n",
    "optimizer_conv = optim.SGD(newModel.fc.parameters(), lr=1e-3, momentum=0.8)\n",
    "\n",
    "# Use decaying scheduler\n",
    "exponentialDecayScheduler = lr_scheduler.StepLR(optimizer_conv, step_size=8, gamma=1e-1)\n",
    "\n",
    "# Train last layer\n",
    "newModel = train(newModel, loss, optimizer_conv, exponentialDecayScheduler, numEpochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "train accuracy: 91.19%\n",
      "valid accuracy: 97.60%\n",
      "Best validation accurracy: 97.602398%\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################################\n",
    "## Train all layers\n",
    "\n",
    "# Unfreeze all layers\n",
    "for param in newModel.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Send to GPU to reduce overhead\n",
    "newModel = newModel.to(device)\n",
    "\n",
    "# Define sigmoid for loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer for back propogation\n",
    "optimizer_conv = optim.SGD(newModel.fc.parameters(), lr=1e-5, momentum=0.8)\n",
    "\n",
    "# Use decaying scheduler\n",
    "exponentialDecayScheduler = lr_scheduler.StepLR(optimizer_conv, step_size=8, gamma=1e-2)\n",
    "\n",
    "# Train all layers\n",
    "newModel = train(newModel, loss, optimizer_conv,exponentialDecayScheduler, numEpochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 97.39%\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################################\n",
    "# Test model on test data\n",
    "test(newModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "train accuracy: 87.49%\n",
      "valid accuracy: 97.90%\n",
      "Best validation accurracy: 97.902098%\n"
     ]
    }
   ],
   "source": [
    "########################## DOMAIN TRANSFERED NETWORK OF RESNET34 ##############################\n",
    "## Train the last layer only\n",
    "\n",
    "# Obtain model\n",
    "newModel = torchvision.models.resnet34(pretrained=True)\n",
    "\n",
    "# Freeze all layers\n",
    "for param in newModel.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace last layer with new, unfrozen layer\n",
    "oldFCInputCount = newModel.fc.in_features\n",
    "totalClassCount = 2\n",
    "newModel.fc = nn.Linear(oldFCInputCount, totalClassCount)\n",
    "\n",
    "\n",
    "# Send to GPU to reduce overhead\n",
    "newModel = newModel.to(device)\n",
    "\n",
    "# Define sigmoid for loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer for back propogation\n",
    "optimizer_conv = optim.SGD(newModel.fc.parameters(), lr=1e-3, momentum=0.8)\n",
    "\n",
    "# Use decaying scheduler\n",
    "exponentialDecayScheduler = lr_scheduler.StepLR(optimizer_conv, step_size=8, gamma=1e-1)\n",
    "\n",
    "# Train last layer\n",
    "newModel = train(newModel, loss, optimizer_conv, exponentialDecayScheduler, numEpochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "train accuracy: 92.92%\n",
      "valid accuracy: 97.70%\n",
      "Best validation accurracy: 97.702298%\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################################\n",
    "## Train all layers\n",
    "\n",
    "# Unfreeze all layers\n",
    "for param in newModel.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Send to GPU to reduce overhead\n",
    "newModel = newModel.to(device)\n",
    "\n",
    "# Define sigmoid for loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer for back propogation\n",
    "optimizer_conv = optim.SGD(newModel.fc.parameters(), lr=1e-5, momentum=0.8)\n",
    "\n",
    "# Use decaying scheduler\n",
    "exponentialDecayScheduler = lr_scheduler.StepLR(optimizer_conv, step_size=8, gamma=1e-2)\n",
    "\n",
    "# Train all layers\n",
    "newModel = train(newModel, loss, optimizer_conv,exponentialDecayScheduler, numEpochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 97.44%\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################################\n",
    "# Test model on test data\n",
    "test(newModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: due to computational limitations, I only used one epoch for the last two parts and two epochs for the first\n",
    "# part. This entire segment of code took two hours for my computer to run so I didn't want to push its limits too far.\n",
    "# I can guarantee the code is fully capable of taking in more epochs and runs efficiently with good hardware!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
